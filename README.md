The PreSumm model leverages Bidirectional Encoder Representations from Transformers (BERT) to advance the field of text summarization, encompassing both extractive and abstractive approaches. For abstractive summarization, PreSumm introduces a novel document-level encoder based on BERT, which effectively captures the semantics of a document and generates sentence representations. The code is based on the following research paper https://arxiv.org/pdf/1908.08345v2
